{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bound-quarterly",
   "metadata": {},
   "source": [
    "<center><h1> bolasso demonstration </h1></center>\n",
    "\n",
    "## In this file, we carefully show the output of the key steps in \"bolasso_parallel.py\" (the parallel version of bolasso)\n",
    "## Please read the comments and explanations in \"bolasso_parallel.py\" first.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-circus",
   "metadata": {},
   "source": [
    "## Preparation 1: we import all the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "southwest-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from matplotlib.ticker    import MaxNLocator\n",
    "from joblib               import Parallel, delayed\n",
    "from sklearn.linear_model import LassoLarsCV, LinearRegression\n",
    "from sklearn.exceptions   import ConvergenceWarning\n",
    "from sklearn              import preprocessing\n",
    "from importlib.metadata   import version\n",
    "\n",
    "assert version('scikit-learn') <= '1.2.0', \"Please make sure the scikit-learn version <= 1.2.0\"\n",
    "\n",
    "# For recent version of Scikit-learn: since the class 'Lars' may rely on the Cholesky decomposition and hence may have potential convergence warning in high dimensional data (p is much larger than n), we input the following commmand to skip the convergence warning.\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-disposal",
   "metadata": {},
   "source": [
    "\n",
    "## Preparation 2 : we define the data generator for simulations (which is copied from \"simulator.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alternative-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simul:\n",
    "\n",
    "    def __init__(self, sample_size, n_dim, n_info):\n",
    "    ##for convinience, we define the common variable (variables we need to use for each of the following functions) in the class as follows (the common variable is defined as self.xxxx)\n",
    "\n",
    "        self.sample_size   = sample_size\n",
    "        self.n_dim         = n_dim\n",
    "        self.n_info        = n_info\n",
    "\n",
    "\n",
    "    #data-generating process\n",
    "    def data_gen(self):\n",
    "\n",
    "        ##1. generating the covariance matrix for X,\n",
    "        #we add a matrix full of 1/2 with an identity matrix multiplied with 1/2\n",
    "        a = np.ones((self.n_dim, self.n_dim)) * 0.5; A = np.eye(self.n_dim)*0.5\n",
    "\n",
    "        cov_x = a + A\n",
    "\n",
    "        ##2. generating the mean of each column in X (which is 0)\n",
    "        mean_x = np.zeros(self.n_dim)\n",
    "\n",
    "        ##3. generating X as a multivariate Gaussian\n",
    "        X = np.random.multivariate_normal(mean_x, cov_x, self.sample_size)\n",
    "\n",
    "        ##4. generate regression coefficients in DGP as an increasing sequence (2,3,4,5,6 in our paper)\n",
    "        beta_info = np.arange(2, self.n_info + 2)\n",
    "\n",
    "        #in DGP, generate regression coefficients of redundant variables as 0\n",
    "        #concatenate the regression coefficients of informative variables and redundant variables\n",
    "        beta = np.concatenate((beta_info, np.zeros(self.n_dim - self.n_info)), axis = 0)\n",
    "\n",
    "        ##5. generate the Gaussian random noise\n",
    "        noise = np.random.normal(0, 1, self.sample_size)\n",
    "\n",
    "        #transform Gaussian random noise into a column\n",
    "        #transform regression coefficients in DGP into a row (based on the requirement of np.inner )\n",
    "        noise.shape = (self.sample_size, 1); beta.shape = (1, self.n_dim)\n",
    "\n",
    "        ##6. generate Y by adding random noise with the inner product of X and beta\n",
    "        Y = np.inner(X,beta) + noise\n",
    "\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-thong",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Now we show the output of key steps in \"bolasso_parallel.py\"\n",
    "* <font size=\"4.5\"> using a parallel for-loop (coded with Joblib), bolasso trains a lasso on each bootstrap sample (based on a child random seed)</font>\n",
    "\n",
    "## #1. firstly,  we only run the parallel for-loop once and check \n",
    "* <font size=\"4.5\"> the random seed generation </font>\n",
    "* <font size=\"4.5\"> bootstrapping and bootstrap sample </font>\n",
    "* <font size=\"4.5\"> the lasso result on first bootstrap sample </font>\n",
    "* <font size=\"4.5\"> the variable \"qhat_k\" that we use to represent which variable is picked by lasso </font>\n",
    "\n",
    "### after turning step 3 and 4 into comments, we only show the output of the first repetition in step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pointed-investing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bolasso:\n",
    "\n",
    "    def __init__(self, X, Y, n_repeat_bolasso, rnd=0):\n",
    "        # for convinience, we define the common variable (variables we need to use for each of the following functions) in the class as follows (the common variable is defined as self.xxxx)\n",
    "\n",
    "        # sample size\n",
    "        self.sample_size = X.shape[0]\n",
    "        # the number of subsamples generated in bolasso\n",
    "        self.n_repeat_bolasso = n_repeat_bolasso\n",
    "        # the number of total variables in X\n",
    "        self.n_dim = X.shape[1]\n",
    "        # randome seeds for parallel computations\n",
    "        self.rnd = rnd\n",
    "        # the maximum value of subsample selection frequency for plotting\n",
    "        self.q_start = 1\n",
    "        # the minimum value of subsample selection frequency for plotting\n",
    "        self.q_end = 0.1\n",
    "        # the sample we generate via data-generating process\n",
    "        self.X = X; self.y = Y\n",
    "\n",
    "    def fit(self):\n",
    "\n",
    "        #1. construct a placeholder called 'qhat_k_container', which is the list of all qhat^k (a binary string representing whether each variable is selected by lasso on subsample k) of each subsample\n",
    "        qhat_k_container = list()\n",
    "\n",
    "        #2. train a lasso on each subsample, find out which variable is selected on a given sample and save the corresponding selection result on subsample k as qhat^k\n",
    "\n",
    "        #parallel computing starts\n",
    "        # 2a. to make parallel computing replicable, set random seeds\n",
    "        np.random.seed(self.rnd)\n",
    "        # 2b. spawn off child seed sequences to pass to child processes.\n",
    "        seeds = np.random.randint(1e8, size=self.n_repeat_bolasso)\n",
    "\n",
    "        # 2c. first we define what we do in each stage of the loop\n",
    "        def loop_fun(self, i, seeds, qhat_k_container):\n",
    "\n",
    "            # 2c(1). fix random seed for replication\n",
    "            np.random.seed(seeds[i])\n",
    "\n",
    "            # 2c(2). randomly choose a bootstrap set of sample points (whose index is 'index_subsample'); \n",
    "            # e.g. choosing n points from n points with replacement\n",
    "            index_subsample = np.random.choice(self.sample_size, self.sample_size, replace=True)\n",
    "            # 2c(3). based on the index \"index_subsample\", take the corresponding observations of X as \"X_subample\"\n",
    "            X_subsample = self.X[index_subsample]\n",
    "            # 2c(4). based on the index \"index_subsample\", take the corresponding observations of Y as \"y_subample\"\n",
    "            y_subsample = self.y[index_subsample]\n",
    "\n",
    "            # 2c(5). change dimension for the Sklearn lasso package.\n",
    "            y_subsample.shape = (y_subsample.shape[0],)\n",
    "            \n",
    "            #standardize training data\n",
    "            scaler = preprocessing.StandardScaler().fit(X_subsample)\n",
    "            X_subsample = scaler.transform(X_subsample)\n",
    "\n",
    "            # 2c(6). given a subsample, compute lasso and output the active set;\n",
    "            # call the lasso class and set the number of fold as 10\n",
    "            trial_1 = LassoLarsCV(cv=10, normalize=False)\n",
    "            # fit lasso on the subsample\n",
    "            trial_1.fit(X_subsample, y_subsample)\n",
    "            # save the lasso active set (indices of variables select by lassso) as 'active'.\n",
    "            active = trial_1.active_\n",
    "\n",
    "            # 2c(7). based on the active set of lasso, we compute qhat^k as the binary string of whether each variable is selected by lasso on subsample K\n",
    "            # we generate 'qhat_k' as a row of zeros;\n",
    "            qhat_k = np.zeros((1, self.n_dim))\n",
    "            # if a variable (the ith column in matrix X) is selected by lasso, we change the ith value of qhat_k (the ith column) as 1\n",
    "            for i in active:\n",
    "\n",
    "                qhat_k[0, i] = 1\n",
    "\n",
    "            # we append the result into 'qhat_k_container' as one element of the list\n",
    "            qhat_k_container.append(qhat_k)\n",
    "\n",
    "            return seeds, index_subsample, X_subsample, y_subsample, active, qhat_k_container\n",
    "        \n",
    "        seeds, index_subsample, X_subsample, y_subsample, active, qhat_k_container = loop_fun(self, 0, seeds, qhat_k_container)\n",
    "        \n",
    "        return seeds, index_subsample, X_subsample, y_subsample, active, qhat_k_container\n",
    "    \n",
    "    '''\n",
    "        # 2d. parallel the whole for-loop using the function we define previously and save the result\n",
    "        # prefer=\"processes\"  means that we prefer use processes\n",
    "        # n_jobs=-1           means we use all possible processes\n",
    "        qhat_k_container = Parallel(n_jobs=-1, prefer=\"processes\")(delayed(loop_fun)(self, i, seeds, qhat_k_container) for i in range(self.n_repeat_bolasso))\n",
    "\n",
    "        # 3. compute subsample selection frequency for all variables\n",
    "        # 3a. we transform the list of all q_hat^k ('qhat_k_container') into a matrix ('qhat_k_container_matrix')\n",
    "        # axis = 0 means we treat each item as a row in matrix;\n",
    "        # row of the matrix   : the q_hat^k on a given subsample for all variables;\n",
    "        # column of the matrix: the corresponding value of qhat^k for variable \"X_i\" on all subsamples;\n",
    "        qhat_k_container_matrix = np.concatenate(qhat_k_container, axis=0)\n",
    "\n",
    "        # 3b. compute the the value of qhat for each variable (the subsample selection frequency of each variable)\n",
    "        # e.g., compute the mean of each column \n",
    "        qhat_value = np.mean(qhat_k_container_matrix, axis=0)\n",
    "\n",
    "        # 3c. set 'Qc_list' as the container for the subsample selection frequencies of all variables, ranking in decreasing order.\n",
    "        Qc_list = list()\n",
    "        # 3d. set 'c_seq' as the sequence of subsample selection frequency in bolasso\n",
    "        q_step = -0.02  #when I need a detailed subsample frequency table, I take it as -0.01; otherwise, I use -0.02 to speed up the computation. This option virtually have no effect on runtime and accuracy on my PC.\n",
    "        c_seq = np.arange(1, 0.1, q_step)\n",
    "\n",
    "        # 3e. for each value of c, generate Q(c) --- the set of variables with subsample frequency larger or equal to c;\n",
    "        for j in c_seq:\n",
    "            # 3e(1). define 'container' as the placeholder of Q(c) when c == j;\n",
    "            container = list()\n",
    "\n",
    "            for i in range(self.X.shape[1]):\n",
    "                # 3e(2). include all variables into 'container' if their corresponding values in q-hat \n",
    "                # (the subsample selection frequency of X_i) are larger or equal to j;\n",
    "                if (qhat_value[0][i] >= j):\n",
    "\n",
    "                    container.append(i)\n",
    "            # 3e(3). append 'container' (Q(c) when c == j) into 'Qc_list' (the container of Q(c) for all value of c);\n",
    "            Qc_list.append(container)\n",
    "\n",
    "        # 4. pick the variable that are selected most of the time;\n",
    "        # 4a. find the active set and save it as 'Q_opt_c';\n",
    "        # 4a(1). if it is bolasso-H, choose c == 1\n",
    "        Q_opt_c_H = Qc_list[0]\n",
    "        # 4a(2). if it is bolasso-S, choose c == 0.9\n",
    "        Q_opt_c_S = Qc_list[5]\n",
    "\n",
    "        # 5. output the bolasso-S result (Q_opt_c_S is the active set of bolasso-S)\n",
    "        # 5a. if Q_opt_c_S is empty, return a zero array and empty active set\n",
    "        if Q_opt_c_S == []:\n",
    "\n",
    "            bolassoS_coef = np.zeros([self.n_dim, 1])\n",
    "        # 5b. otherwise, regress Y onto the selected variables in X (variables in Q_opt_c_S)\n",
    "        else:\n",
    "            # 5b(1). call the LinearRegression class;\n",
    "            OLS_S = LinearRegression()\n",
    "            # 5b(2). fit OLS of Y to the variables in Q_opt_c_S on X;\n",
    "            OLS_S.fit(self.X[:, Q_opt_c_S], self.y)\n",
    "            # 5b(3). set 'bolassoS_coef' (an array of zeros) as the placeholder of bolasso-S regression coefficents\n",
    "            bolassoS_coef = np.zeros([self.n_dim, 1])\n",
    "            # 5b(4). put the estimated regression coefficents into their corresponding place of 'bolassoS_coef'\n",
    "            bolassoS_coef[Q_opt_c_S, 0] = OLS_S.coef_\n",
    "\n",
    "        # 5c. output the bolasso-H result (Q_opt_c_H is the active set of bolasso-H)\n",
    "        # if Q_opt_c_H is empty, return a zero array and empty active set\n",
    "        if Q_opt_c_H == []:\n",
    "\n",
    "            bolassoH_coef = np.zeros([self.n_dim, 1])\n",
    "        # 5d. otherwise, regress Y onto the selected variables in X (variables in Q_opt_c_H)\n",
    "        else:\n",
    "            # 5d(1). call the LinearRegression class;\n",
    "            OLS_H = LinearRegression()\n",
    "            # 5d(2). fit OLS of Y on the variables of Q_opt_c_H in X;\n",
    "            OLS_H.fit(self.X[:, Q_opt_c_H], self.y)\n",
    "            # 5d(3). set 'bolassoH_coef' (an array of zeros) as the placeholder of bolasso-H regression coefficents\n",
    "            bolassoH_coef = np.zeros([self.n_dim, 1])\n",
    "            # 5d(4). put the estimated regression coefficents into their corresponding place of 'bolassoH_coef'\n",
    "            bolassoH_coef[Q_opt_c_H, 0] = OLS_H.coef_\n",
    "\n",
    "        return bolassoS_coef, bolassoH_coef, Qc_list, Q_opt_c_S, Q_opt_c_H\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-peninsula",
   "metadata": {},
   "source": [
    "### now run the function above under the following simulation setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "contained-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 20\n",
    "n_dim = 12\n",
    "n_info = 5\n",
    "n_repeat_bolasso = 256\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "# generate X and Y\n",
    "trial1 = simul(sample_size, n_dim, n_info)\n",
    "X, Y = trial1.data_gen()\n",
    "\n",
    "# train bolasso\n",
    "trial2 = bolasso(X, Y, n_repeat_bolasso)\n",
    "\n",
    "seeds, index_subsample, X_subsample, y_subsample, active, qhat_k_container = trial2.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-italian",
   "metadata": {},
   "source": [
    "## Now let's check the result\n",
    "\n",
    "### check all 256 random seeds for each lasso repetition in bolasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exciting-supervision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75434668  2215104 38712131 60969723 58554051 15039847 74753033 89739541\n",
      " 40294130   374564 69941847 72039494 97308044 36256058 38290113 44989926\n",
      " 48220334 23813720 76385105 83093157 36662093 99522452 86837363 86414067\n",
      " 84418245 65931087 42384210 20865123 76916696 84442289 87950109 97193107\n",
      "  8085927 64085280 83836865 78826761 26299065 30790271 37003808 93837855\n",
      " 52216522 36129012 20832407 62515875 78031730 80102583 25486114 43886720\n",
      " 80701568 49997732 78794278 15338984 99574516 49344785 26835279 53472298\n",
      " 67679674 82950687 43513153 23752679  4548665 45168931 61795447 62962443\n",
      " 98279854 61856850 16863323  2946944 12577166 60476003 85730869 53889932\n",
      " 33057401 30818218  4730964 39831755 84283716 92123910 35625924 91812479\n",
      " 43202548 21730435 83109044 14137320 34869070 25544340 11680535 71404429\n",
      " 79466869   341845 20193840 56620337 39008425 51844771 26958943 36478149\n",
      " 58289758 14393600 74773796 10086306 13722416 33111901 13715843 41336362\n",
      " 34407373 47654887 58665877 88105161 85846399 34092544 18085770  6687090\n",
      " 46543403 67407231 63952919 52156091  4987257 23550050 23518782 34415523\n",
      " 51477214  7075963 21355090 11548590 17615587 91708564 66097361 38521394\n",
      " 99849627 44981006   818217 64027706 57752257 88529956 98982666 26065963\n",
      " 40186728 47933451 29196595 95237200 35030144 63265574 98014382 92648819\n",
      " 86361272 37325244 70609384 20166942 92091672 92627581 30573314 85933571\n",
      " 69738590 70626530 31037291 26228040 58657811 90616415 90359194 41884098\n",
      " 59790584 18604212 71100739 65493996 41340686 50241376 11418884 42180547\n",
      " 51450605 96430219 69522428 73116246  5574093 23923577 92366445 82416459\n",
      " 26213048 80628888  3085213 28928149 21610521 27935676 14681977  5688182\n",
      "  8402037 79816125 50607699 81562273 85337960 75613088 54302203 26274555\n",
      " 82434169  5936454 87294421 16851469 28952391 37914296 36344984 96717074\n",
      " 14827048 44985782 39141583 73153291 32061551 44223837 88331393 50789087\n",
      " 10200950   909528 36495384 10791890 92541935 69852931 15075020 65679651\n",
      " 72685270 44413950 24792773 70388439 44780075 27818016 24992779 56833640\n",
      " 36772052  2143926 27098600 26813186 35714587 93671379 45515993 18288947\n",
      " 90981550 22105013 28349981 64306755  4008483  8471335 28634505 59377737\n",
      " 42643753 68902787 59379502 14197466 83056562 97205100 93398787 29083423\n",
      " 71416585 51768714 51506715 50311597 64045255 69698983 28447805 48277845]\n"
     ]
    }
   ],
   "source": [
    "print(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "conscious-martial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-possible",
   "metadata": {},
   "source": [
    "## check the orignal sample index for each observation in the bootstrap sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tender-cocktail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['point 10', 'point 19', 'point 7', 'point 8', 'point 11', 'point 7', 'point 19', 'point 10', 'point 9', 'point 14', 'point 18', 'point 16', 'point 13', 'point 14', 'point 17', 'point 16', 'point 14', 'point 0', 'point 7', 'point 13']\n"
     ]
    }
   ],
   "source": [
    "obs_index = ['point ' + str(i) for i in index_subsample]\n",
    "print(obs_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-patch",
   "metadata": {},
   "source": [
    "### and the corresponding dot plot\n",
    "* <font size=\"4.5\"> horizontal axis is the observation index in orignal sample </font>\n",
    "* <font size=\"4.5\"> if you find 3 dots on horizontal value \"7\", in this bootstrap sample, point 7 from the original sample appears 3 times </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "preliminary-poland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x160 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = 20\n",
    "\n",
    "fig1 = plt.figure(figsize=(15, 2), dpi=80)\n",
    "hist, edges = np.histogram(index_subsample, bins=bins)\n",
    "\n",
    "y  = np.arange(1,hist.max()+1)\n",
    "x  = np.arange(bins)\n",
    "X,Y = np.meshgrid(x,y)\n",
    "\n",
    "plt.scatter(X,Y, c=Y<=hist, cmap=\"Greys\")\n",
    "\n",
    "ax = fig1.gca()\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.xlabel(\"the observation index in orginal sample\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-kruger",
   "metadata": {},
   "source": [
    "## check the bootstrap sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "virtual-albany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of obs and the number of variables in a bootstrap sample : (20, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"the number of obs and the number of variables in a bootstrap sample :\", X_subsample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "desirable-margin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of obs in a bootstrap sample : (20,)\n"
     ]
    }
   ],
   "source": [
    "print(\"the number of obs in a bootstrap sample :\", y_subsample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-murray",
   "metadata": {},
   "source": [
    "## check the lasso active set on the first bootstrap sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "willing-candy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the active set of lasso : [4, 1, 7, 2, 3, 0, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "print(\"the active set of lasso :\", active)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-oxide",
   "metadata": {},
   "source": [
    "## check variable \"qhat_k\" on the first bootstrap sample\n",
    "* <font size=\"4.5\"> if you find the $i^{th}$ value in \"qhat_k\" is 1, the $i^{th}$ variable is selected on this bootstrap sample</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "certain-verification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the qhat for each varaible in X on the first bootstrap sample\n",
      "[array([[1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.]])]\n"
     ]
    }
   ],
   "source": [
    "print(\"the qhat for each varaible in X on the first bootstrap sample\")\n",
    "print(qhat_k_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-publicity",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## #2. now, let's check \n",
    "* <font size=\"4.5\"> the qhat for 256 bootstrap samples </font>\n",
    "* <font size=\"4.5\"> the subsample selection frequency of all variables </font>\n",
    "* <font size=\"4.5\"> active set of bolasso-S and bolasso-H </font>\n",
    "\n",
    "### we turning the last step into comments since it only produces the post-bolasso OLS coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "burning-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bolasso:\n",
    "\n",
    "    def __init__(self, X, Y, n_repeat_bolasso, rnd=0):\n",
    "        # for convinience, we define the common variable (variables we need to use for each of the following functions) in the class as follows (the common variable is defined as self.xxxx)\n",
    "\n",
    "        # sample size\n",
    "        self.sample_size = X.shape[0]\n",
    "        # the number of subsamples generated in bolasso\n",
    "        self.n_repeat_bolasso = n_repeat_bolasso\n",
    "        # the number of total variables in X\n",
    "        self.n_dim = X.shape[1]\n",
    "        # randome seeds for parallel computations\n",
    "        self.rnd = rnd\n",
    "        # the maximum value of subsample selection frequency for plotting\n",
    "        self.q_start = 1\n",
    "        # the minimum value of subsample selection frequency for plotting\n",
    "        self.q_end = 0.1\n",
    "        # the sample we generate via data-generating process\n",
    "        self.X = X; self.y = Y\n",
    "\n",
    "    def fit(self):\n",
    "\n",
    "        #1. construct a placeholder called 'qhat_k_container', which is the list of all qhat^k (a binary string representing whether each variable is selected by lasso on subsample k) of each subsample\n",
    "        qhat_k_container = list()\n",
    "\n",
    "        #2. train a lasso on each subsample, find out which variable is selected on a given sample and save the corresponding selection result on subsample k as qhat^k\n",
    "\n",
    "        #parallel computing starts\n",
    "        # 2a. to make parallel computing replicable, set random seeds\n",
    "        np.random.seed(self.rnd)\n",
    "        # 2b. spawn off child seed sequences to pass to child processes.\n",
    "        seeds = np.random.randint(1e8, size=self.n_repeat_bolasso)\n",
    "\n",
    "        # 2c. first we define what we do in each stage of the loop\n",
    "        def loop_fun(self, i, seeds, qhat_k_container):\n",
    "\n",
    "            # 2c(1). fix random seed for replication\n",
    "            np.random.seed(seeds[i])\n",
    "\n",
    "            # 2c(2). randomly choose a bootstrap set of sample points (whose index is 'index_subsample'); \n",
    "            # e.g. choosing n points from n points with replacement\n",
    "            index_subsample = np.random.choice(self.sample_size, self.sample_size, replace=True)\n",
    "            # 2c(3). based on the index \"index_subsample\", take the corresponding observations of X as \"X_subample\"\n",
    "            X_subsample = self.X[index_subsample]\n",
    "            # 2c(4). based on the index \"index_subsample\", take the corresponding observations of Y as \"y_subample\"\n",
    "            y_subsample = self.y[index_subsample]\n",
    "\n",
    "            # 2c(5). change dimension for the Sklearn lasso package.\n",
    "            y_subsample.shape = (y_subsample.shape[0],)\n",
    "            \n",
    "            #standardize training data\n",
    "            scaler = preprocessing.StandardScaler().fit(X_subsample)\n",
    "            X_subsample = scaler.transform(X_subsample)\n",
    "\n",
    "            # 2c(6). given a subsample, compute lasso and output the active set;\n",
    "            # call the lasso class and set the number of fold as 10\n",
    "            trial_1 = LassoLarsCV(cv=10, normalize=False)\n",
    "            # fit lasso on the subsample\n",
    "            trial_1.fit(X_subsample, y_subsample)\n",
    "            # save the lasso active set (indices of variables select by lassso) as 'active'.\n",
    "            active = trial_1.active_\n",
    "\n",
    "            # 2c(7). based on the active set of lasso, we compute qhat^k as the binary string of whether each variable is selected by lasso on subsample K\n",
    "            # we generate 'qhat_k' as a row of zeros;\n",
    "            qhat_k = np.zeros((1, self.n_dim))\n",
    "            # if a variable (the ith column in matrix X) is selected by lasso, we change the ith value of qhat_k (the ith column) as 1\n",
    "            for i in active:\n",
    "\n",
    "                qhat_k[0, i] = 1\n",
    "\n",
    "            # we append the result into 'qhat_k_container' as one element of the list\n",
    "            qhat_k_container.append(qhat_k)\n",
    "\n",
    "            return qhat_k_container\n",
    "    \n",
    "        # 2d. parallel the whole for-loop using the function we define previously and save the result\n",
    "        # prefer=\"processes\"  means that we prefer use processes\n",
    "        # n_jobs=-1           means we use all possible processes\n",
    "        qhat_k_container = Parallel(n_jobs=-1, prefer=\"processes\")(delayed(loop_fun)(self, i, seeds, qhat_k_container) for i in range(self.n_repeat_bolasso))\n",
    "\n",
    "        # 3. compute subsample selection frequency for all variables\n",
    "        # 3a. we transform the list of all q_hat^k ('qhat_k_container') into a matrix ('qhat_k_container_matrix')\n",
    "        # axis = 0 means we treat each item as a row in matrix;\n",
    "        # row of the matrix   : the q_hat^k on a given subsample for all variables;\n",
    "        # column of the matrix: the corresponding value of qhat^k for variable \"X_i\" on all subsamples;\n",
    "        qhat_k_container_matrix = np.concatenate(qhat_k_container, axis=0)\n",
    "\n",
    "        # 3b. compute the the value of qhat for each variable (the subsample selection frequency of each variable)\n",
    "        # e.g., compute the mean of each column \n",
    "        qhat_value = np.mean(qhat_k_container_matrix, axis=0)\n",
    "\n",
    "        # 3c. set 'Qc_list' as the container for the subsample selection frequencies of all variables, ranking in decreasing order.\n",
    "        Qc_list = list()\n",
    "        # 3d. set 'c_seq' as the sequence of subsample selection frequency in bolasso\n",
    "        q_step = -0.02  #when I need a detailed subsample frequency table, I take it as -0.01; otherwise, I use -0.02 to speed up the computation. This option virtually have no effect on runtime and accuracy on my PC.\n",
    "        c_seq = np.arange(1, 0.1, q_step)\n",
    "\n",
    "        # 3e. for each value of c, generate Q(c) --- the set of variables with subsample frequency larger or equal to c;\n",
    "        for j in c_seq:\n",
    "            # 3e(1). define 'container' as the placeholder of Q(c) when c == j;\n",
    "            container = list()\n",
    "\n",
    "            for i in range(self.X.shape[1]):\n",
    "                # 3e(2). include all variables into 'container' if their corresponding values in q-hat \n",
    "                # (the subsample selection frequency of X_i) are larger or equal to j;\n",
    "                if (qhat_value[0][i] >= j):\n",
    "\n",
    "                    container.append(i)\n",
    "            # 3e(3). append 'container' (Q(c) when c == j) into 'Qc_list' (the container of Q(c) for all value of c);\n",
    "            Qc_list.append(container)\n",
    "\n",
    "        # 4. pick the variable that are selected most of the time;\n",
    "        # 4a. find the active set and save it as 'Q_opt_c';\n",
    "        # 4a(1). if it is bolasso-H, choose c == 1\n",
    "        Q_opt_c_H = Qc_list[0]\n",
    "        # 4a(2). if it is bolasso-S, choose c == 0.9\n",
    "        Q_opt_c_S = Qc_list[5]\n",
    "        \n",
    "        return qhat_k_container, qhat_value, Qc_list, Q_opt_c_H, Q_opt_c_S\n",
    "        \n",
    "        '''\n",
    "        # 5. output the bolasso-S result (Q_opt_c_S is the active set of bolasso-S)\n",
    "        # 5a. if Q_opt_c_S is empty, return a zero array and empty active set\n",
    "        if Q_opt_c_S == []:\n",
    "\n",
    "            bolassoS_coef = np.zeros([self.n_dim, 1])\n",
    "        # 5b. otherwise, regress Y onto the selected variables in X (variables in Q_opt_c_S)\n",
    "        else:\n",
    "            # 5b(1). call the LinearRegression class;\n",
    "            OLS_S = LinearRegression()\n",
    "            # 5b(2). fit OLS of Y to the variables in Q_opt_c_S on X;\n",
    "            OLS_S.fit(self.X[:, Q_opt_c_S], self.y)\n",
    "            # 5b(3). set 'bolassoS_coef' (an array of zeros) as the placeholder of bolasso-S regression coefficents\n",
    "            bolassoS_coef = np.zeros([self.n_dim, 1])\n",
    "            # 5b(4). put the estimated regression coefficents into their corresponding place of 'bolassoS_coef'\n",
    "            bolassoS_coef[Q_opt_c_S, 0] = OLS_S.coef_\n",
    "\n",
    "        # 5c. output the bolasso-H result (Q_opt_c_H is the active set of bolasso-H)\n",
    "        # if Q_opt_c_H is empty, return a zero array and empty active set\n",
    "        if Q_opt_c_H == []:\n",
    "\n",
    "            bolassoH_coef = np.zeros([self.n_dim, 1])\n",
    "        # 5d. otherwise, regress Y onto the selected variables in X (variables in Q_opt_c_H)\n",
    "        else:\n",
    "            # 5d(1). call the LinearRegression class;\n",
    "            OLS_H = LinearRegression()\n",
    "            # 5d(2). fit OLS of Y on the variables of Q_opt_c_H in X;\n",
    "            OLS_H.fit(self.X[:, Q_opt_c_H], self.y)\n",
    "            # 5d(3). set 'bolassoH_coef' (an array of zeros) as the placeholder of bolasso-H regression coefficents\n",
    "            bolassoH_coef = np.zeros([self.n_dim, 1])\n",
    "            # 5d(4). put the estimated regression coefficents into their corresponding place of 'bolassoH_coef'\n",
    "            bolassoH_coef[Q_opt_c_H, 0] = OLS_H.coef_\n",
    "\n",
    "        return bolassoS_coef, bolassoH_coef, Qc_list, Q_opt_c_S, Q_opt_c_H\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-discount",
   "metadata": {},
   "source": [
    "### now run the function above under the following simulation setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "assured-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size      = 100\n",
    "n_dim            = 12\n",
    "n_info           = 5\n",
    "n_repeat_bolasso = 256\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "# generate X and Y\n",
    "trial1 = simul(sample_size, n_dim, n_info)\n",
    "X, Y = trial1.data_gen()\n",
    "\n",
    "# train bolasso\n",
    "trial2 = bolasso(X, Y, n_repeat_bolasso)\n",
    "\n",
    "qhat_k_container, qhat_value, Qc_list, Q_opt_c_H, Q_opt_c_S = trial2.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-casino",
   "metadata": {},
   "source": [
    "### check the qhat for first 5 subsamples of bolasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "warming-surveillance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.]])],\n",
       " [array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])],\n",
       " [array([[1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.]])],\n",
       " [array([[1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.]])],\n",
       " [array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qhat_k_container[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-alberta",
   "metadata": {},
   "source": [
    "### check the subsample selection frequency of each varaible on 256 subsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "confirmed-nashville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         1.         1.         1.         0.56640625\n",
      "  0.61328125 0.9609375  0.61328125 0.74609375 0.8515625  0.62890625]]\n"
     ]
    }
   ],
   "source": [
    "print(qhat_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-veteran",
   "metadata": {},
   "source": [
    "### and the corresponding barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "israeli-imperial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = np.arange(12)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,3))\n",
    "\n",
    "ax.bar(ind, qhat_value[0], 0.35, edgecolor=\"black\", color=\"white\")\n",
    "ax.hlines(1, -1, 13, linewidth=3, color='red', linestyles='dashed')\n",
    "ax.hlines(0.9, -1, 13, linewidth=3, color='green', linestyles='dashed')\n",
    "\n",
    "ax.set_xlim([-0.5, 11.5])\n",
    "ax.set_ylim([0.5, 1.02])\n",
    "\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.xlabel(\"the index of each varaible in X\")\n",
    "plt.ylabel(\"subsample selection frequency\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-beauty",
   "metadata": {},
   "source": [
    "## check the active set of bolasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "latter-croatia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the active set with f=1.0 : [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"the active set with f=1.0 :\", Q_opt_c_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "emotional-elimination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the active set with f=0.9 : [0, 1, 2, 3, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "print(\"the active set with f=0.9 :\", Q_opt_c_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-stock",
   "metadata": {},
   "source": [
    "## finaly, producing this into html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "accepted-afternoon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook bolasso_walkthrough.ipynb to html\n",
      "[NbConvertApp] Writing 662464 bytes to bolasso_walkthrough.html\n"
     ]
    }
   ],
   "source": [
    "!rm -rf bolasso_walkthrough.html\n",
    "!jupyter nbconvert --to html bolasso_walkthrough.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-indonesian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
